# LLM Fine-Tuning Configuration
# See QUICK_START.md for usage guide and presets at bottom of file

# ============================================================================
# CLUSTER CONFIGURATION
# ============================================================================
cluster:
  nodes: 2                   # Number of compute nodes
  gpus_per_node: 2           # GPUs per node (4x H200 in PoC allocation)
  partition: "main"          # SLURM partition (check with: sinfo)

# ============================================================================
# STORAGE CONFIGURATION
# ============================================================================
storage:
  shared_fs: "/shared/llm-fine-tune"      # Shared filesystem (2TB SSD)
  network_disk: "/mnt/network-disk"       # Network disk (2TB SSD)
  
  # Paths (relative to shared_fs)
  data_dir: "data"
  checkpoint_dir: "checkpoints"
  log_dir: "logs"
  cache_dir: "cache"

# ============================================================================
# MODEL CONFIGURATION
# ============================================================================
model:
  # Base model to fine-tune
  # Small (1-3B): Qwen/Qwen2.5-1.5B-Instruct, microsoft/Phi-3-mini-4k-instruct
  # Medium (7-8B): Qwen/Qwen2.5-7B-Instruct, meta-llama/Llama-3.1-8B-Instruct
  # Large (14-70B): Qwen/Qwen2.5-14B-Instruct, meta-llama/Llama-3.1-70B-Instruct
  model_id: "Qwen/Qwen2.5-7B-Instruct"
  
  torch_dtype: "bfloat16"
  use_flash_attention: false  # Set to true if flash-attn is installed (H100/H200 optimization)
  cache_dir: "${storage.network_disk}/model_cache"

# ============================================================================
# DATASET CONFIGURATION
# ============================================================================
dataset:
  # Dataset source for function calling
  # Options: glaiveai/glaive-function-calling-v2 (113k), 
  #          Salesforce/xlam-function-calling-60k (60k),
  #          NousResearch/hermes-function-calling-v1 (115k)
  name: "glaiveai/glaive-function-calling-v2"
  
  split: "train"             # Dataset split to use
  max_samples: 10000          # Number of samples (null = use all)
  streaming: true            # Memory efficient for large datasets
  text_field: "chat"         # Text field name in dataset

# ============================================================================
# LORA CONFIGURATION
# ============================================================================
lora:
  r: 16                      # LoRA rank (8=fast, 16=balanced, 32=quality)
  lora_alpha: 32             # LoRA scaling factor
  lora_dropout: 0.05         # Dropout for LoRA layers
  bias: "none"               # Bias training: "none", "all", "lora_only"
  
  target_modules:            # Target modules for LoRA
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"

# ============================================================================
# TRAINING CONFIGURATION
# ============================================================================
training:
  num_train_epochs: 1
  max_steps: -1              # -1 = use num_train_epochs
  
  # Batch size (effective = per_device × gradient_accum × num_gpus)
  per_device_train_batch_size: 8
  gradient_accumulation_steps: 4
  
  learning_rate: 2.0e-4
  lr_scheduler_type: "linear"  # Options: linear, cosine, constant
  warmup_ratio: 0.03           # Fraction of training for warmup
  
  optim: "adamw_torch"
  weight_decay: 0.01
  max_grad_norm: 1.0
  
  # Precision
  bf16: true
  fp16: false
  
  max_seq_length: 2048
  packing: false             # Keep false for function calling

# ============================================================================
# DISTRIBUTED TRAINING CONFIGURATION
# ============================================================================
distributed:
  strategy: "fsdp"           # Options: fsdp (multi-GPU), ddp (single-node)
  
  fsdp:
    enabled: true
    sharding_strategy: "full_shard"        # full_shard, shard_grad_op, no_shard
    auto_wrap_policy: "transformer_based_wrap"
    backward_prefetch: "backward_pre"
    cpu_offload: false       # Enable if running out of GPU memory
  
  ddp:
    find_unused_parameters: false
    gradient_as_bucket_view: true

# ============================================================================
# CHECKPOINTING CONFIGURATION
# ============================================================================
checkpointing:
  save_strategy: "steps"     # Options: steps, epoch, no
  save_steps: 25             # Save frequency
  save_total_limit: 3        # Max checkpoints to keep (null = keep all)
  resume_from_checkpoint: true
  save_optimizer: true       # Save optimizer state for exact resumption

# ============================================================================
# LOGGING & MONITORING CONFIGURATION
# ============================================================================
logging:
  logging_steps: 1           # Log frequency
  report_to: "tensorboard"   # Options: none, tensorboard, wandb, all
  
  tensorboard:
    enabled: true
    log_dir: "runs"
  
  wandb:
    enabled: false
    project: "llm-fine-tune"
    entity: null
    run_name: null

# ============================================================================
# VALIDATION CONFIGURATION
# ============================================================================
validation:
  enabled: true
  dataset: null              # null = split from training data
  validation_split: 0.05     # Reserve 5% for validation
  eval_strategy: "steps"     # Options: steps, epoch, no
  eval_steps: 25             # Evaluation frequency
  
  metrics:
    - "loss"
    - "perplexity"
    - "token_accuracy"

# ============================================================================
# PERFORMANCE BENCHMARKING
# ============================================================================
benchmarking:
  enabled: true
  track_gpu_utilization: true
  track_throughput: true
  track_memory: true
  output_file: "logs/benchmark_results.json"

# ============================================================================
# INFERENCE CONFIGURATION
# ============================================================================
inference:
  test_prompts:
    - role: "system"
      content: "You are a helpful AI assistant with function calling capabilities."
    - role: "user"
      content: "Book a flight from New York to San Francisco on March 15th for 2 passengers."
  
  max_new_tokens: 256
  temperature: 0.7
  top_p: 0.9
  do_sample: true

# ============================================================================
# CONFIGURATION PRESETS
# ============================================================================
# Copy these into the sections above to quickly configure for different scenarios
#
# PRESET 1: Fast PoC (5-15 minutes)
# model_id: "Qwen/Qwen2.5-1.5B-Instruct"
# max_samples: 10000
# num_train_epochs: 1
# per_device_train_batch_size: 16
# lora r: 8
#
# PRESET 2: Balanced PoC (15-30 minutes) - CURRENT CONFIG
# model_id: "Qwen/Qwen2.5-7B-Instruct"
# max_samples: 20000
# num_train_epochs: 1
# per_device_train_batch_size: 8
# lora r: 16
#
# PRESET 3: Production Quality (2-4 hours)
# model_id: "Qwen/Qwen2.5-7B-Instruct"
# max_samples: 60000
# num_train_epochs: 3
# per_device_train_batch_size: 8
# lora r: 32
#
# PRESET 4: High Quality (4-8 hours)
# model_id: "Qwen/Qwen2.5-14B-Instruct"
# max_samples: null
# num_train_epochs: 3
# per_device_train_batch_size: 4
# lora r: 32
#
# PRESET 5: Memory Constrained
# per_device_train_batch_size: 4
# gradient_accumulation_steps: 8
# lora r: 8
# cpu_offload: true
